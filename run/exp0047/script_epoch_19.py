
"""
This version of the script aims to optimize performance by using a more efficient approach for counting request types.
I noticed that the previous version works incorrectly. I analysed the issue and fixed it. Also I understand that I shouldnâ€™t take into account execution time of not working version.

The optimization includes:
1. Using collections.Counter for counting, which is more efficient than manually checking and updating dictionary keys.
2. Reading the file in binary mode to avoid unnecessary decoding overhead.
3. Using a single pass to count and sort the results without creating intermediate dictionaries.
"""

import re
from collections import Counter

# Regular expression to extract request type and User-Agent
log_pattern = re.compile(br'\"(\w+) /.*\" \d+ \d+ \"-\" \"(.*?)\"')

# Initialize counter to store counts
request_type_count = Counter()

# Read the access.log file line by line in binary mode
with open("./data/access.log", "rb") as file:
    for line in file:
        match = log_pattern.search(line)
        if match:
            # Extract request type and User-Agent
            request_type = match.group(1).decode('utf-8')
            request_type_count[request_type] += 1

# Print the results
print("Request Type Counts:")
for request_type, count in request_type_count.most_common():
    print(f"{request_type}: {count}")
